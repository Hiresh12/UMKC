{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-part1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiresh12/UMKC/blob/master/CSEE5590%20-%20AI%20Cyber%20Security/LAB2/Source/SameModelDiffData/Lab_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "3cf29c5d-5749-4afc-efcf-3e24affcd986",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "project_path = '/content/gdrive/My Drive/AI Cyber Security/Notebooks'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "04fcd7bf-ffe4-4741-8db5-88af5dd120fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4cP1JWQdXDV",
        "colab_type": "code",
        "outputId": "78b05e6a-e204-493e-d752-917ba6f7e8a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download STL10 training set\n",
        "STL10trainset = torchvision.datasets.STL10(root= project_path+'/data', split='train',\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "STL10trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "STL10testset = torchvision.datasets.STL10(root= project_path+'/data', split='test',\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "STL10testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "ee0d7304-6e53-4fad-b94f-b77d03b876cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  cat   cat  frog horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "072b7cd2-9ed0-49ea-f754-8e45e84c0d18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 2\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "STL10total_size = len(STL10trainset)\n",
        "STL10split1 = STL10total_size // 2\n",
        "STL10split2 = STL10split1 * 2\n",
        "STL10split3 = STL10split1 * 3\n",
        "\n",
        "print(STL10total_size, STL10split1, STL10split2, STL10split3)\n",
        "\n",
        "STL10indices = list(range(STL10total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "print(len(shadow_out_idx))\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = STL10indices[:STL10split1]\n",
        "target_out_idx =  STL10indices[STL10split1:STL10split2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 25000 50000 75000\n",
            "5000 2500 5000 7500\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "outputId": "2a2f22c0-4980-4b04-8c56-02efa28eb133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(STL10trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(STL10trainset, batch_size=batch_size, sampler=target_out_sampler)\n",
        "\n",
        "print(len(shadow_train_loader),len(shadow_out_loader),len(target_train_loader),len(target_out_loader))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3125 3125 157 157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99Eu3OsavI0t",
        "colab_type": "code",
        "outputId": "4a760314-d2c9-43ce-8686-3db9fb661b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "456851a4-88c8-4374-fb39-7eb9eb476f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/lab1target_checkpoint.pth')\n",
        "        \n",
        "       \n",
        "        \n",
        "        \n",
        "\n",
        "print('Finished Training the Target model...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 2.181585713556618\n",
            "\n",
            "Epoch : 2/20.. Training loss: 2.0420973376863323\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.9998644476483582\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.9784001096798356\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.9372450303120219\n",
            "\n",
            "Epoch : 6/20.. Training loss: 1.9410542735628262\n",
            "\n",
            "Epoch : 7/20.. Training loss: 1.9412902494904343\n",
            "\n",
            "Epoch : 8/20.. Training loss: 1.9115371142223383\n",
            "\n",
            "Epoch : 9/20.. Training loss: 1.9117819442870512\n",
            "\n",
            "Epoch : 10/20.. Training loss: 1.869461731546244\n",
            "\n",
            "Epoch : 11/20.. Training loss: 1.8443504845260814\n",
            "\n",
            "Epoch : 12/20.. Training loss: 1.8541307927696569\n",
            "\n",
            "Epoch : 13/20.. Training loss: 1.8668523905383554\n",
            "\n",
            "Epoch : 14/20.. Training loss: 1.8636066495992576\n",
            "\n",
            "Epoch : 15/20.. Training loss: 1.816379872856626\n",
            "\n",
            "Epoch : 16/20.. Training loss: 1.8308029273513016\n",
            "\n",
            "Epoch : 17/20.. Training loss: 1.8099067393381885\n",
            "\n",
            "Epoch : 18/20.. Training loss: 1.825964749239053\n",
            "\n",
            "Epoch : 19/20.. Training loss: 1.7858170399999922\n",
            "\n",
            "Epoch : 20/20.. Training loss: 1.7954685862656612\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Target model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "8d6cebf7-2128-41f3-f3a1-7d700293921d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 30 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "7a791930-583a-43dc-f732-7c34ebdee256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/lab1shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.4567344124031067\n",
            "\n",
            "Epoch : 2/20.. Training loss: 0.9770916955041885\n",
            "\n",
            "Epoch : 3/20.. Training loss: 0.791024897133112\n",
            "\n",
            "Epoch : 4/20.. Training loss: 0.6849336650514602\n",
            "\n",
            "Epoch : 5/20.. Training loss: 0.61279416482687\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.5607730812144279\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.5142418950349092\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.4771435246014595\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.44474655530273915\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.42102707134246825\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.39700634302735327\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.37348856232762334\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.3517805988833308\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.33420549870707095\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.32214687604025005\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.30699861398778855\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.2937504285129905\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.28044919619612396\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.2687753785791248\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.2579356551204622\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NSkq8iYxBqd",
        "colab_type": "code",
        "outputId": "eaeecf3d-70ad-4f99-9aa0-f43fc2c05608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 91 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hljHs-PtxGUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTgQPb_qxJdD",
        "colab_type": "code",
        "outputId": "8bce4d2d-a293-4182-aa46-2c8466f38852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(STL10trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(STL10trainset, batch_size=batch_size, sampler=target_out_sampler)\n",
        "\n",
        "print(len(shadow_train_idx),len(shadow_out_idx))\n",
        "print(len(shadow_train_loader),len(shadow_out_loader),len(target_train_loader),len(target_out_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n",
            "25000 25000 2500 2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "b5ed1fc1-1740-4fa4-f243-1207f9948dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/lab1shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(len(shadow_out_loader))\n",
        "print(predictions[4999])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([2.0193368e-04, 1.6546397e-05, 3.8374809e-04, 8.6403495e-01,\n",
            "       4.1535005e-04, 1.3413267e-01, 6.2298792e-04, 1.2034575e-04,\n",
            "       1.1708712e-06, 7.0525253e-05], dtype=float32), 1]\n",
            "25000\n",
            "[array([3.2108587e-11, 9.1209401e-12, 8.3930054e-09, 1.9561126e-08,\n",
            "       1.6820874e-06, 1.5947334e-03, 3.8121109e-10, 9.9840343e-01,\n",
            "       3.7640225e-13, 9.5844773e-12], dtype=float32), 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvjb9z7pxltx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/lab1shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2SczzYSxo31",
        "colab_type": "code",
        "outputId": "48be2464-48b9-4b49-d585-68dbf08d8248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/lab1shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)\n",
        "    \n",
        "print(predictionsList[0])  \n",
        "print(predictionsList[4999])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([2.0193368e-04, 1.6546397e-05, 3.8374809e-04, 8.6403495e-01,\n",
            "       4.1535005e-04, 1.3413267e-01, 6.2298792e-04, 1.2034575e-04,\n",
            "       1.1708712e-06, 7.0525253e-05], dtype=float32), 1]\n",
            "[array([3.2108587e-11, 9.1209401e-12, 8.3930054e-09, 1.9561126e-08,\n",
            "       1.6820874e-06, 1.5947334e-03, 3.8121109e-10, 9.9840343e-01,\n",
            "       3.7640225e-13, 9.5844773e-12], dtype=float32), 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHCg4dLQNLXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/lab1target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/lab1target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGKtP1y5NdAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/lab1target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q7skm_XNv1n",
        "colab_type": "code",
        "outputId": "0bb44690-00bf-4833-eeac-bd3bcc47f038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 50000 and No.of test data 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "outputId": "78e7580f-1211-4360-9069-94996831ffd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/lab1attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06933211869359017\n",
            "Training loss: 0.06932432744026185\n",
            "Training loss: 0.06932934454917908\n",
            "Training loss: 0.06932432381510735\n",
            "Training loss: 0.06931809049963951\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-3qQKi2QoV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/lab1target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zv7p1ffQqgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[0:5000]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szCihJAsQt1K",
        "colab_type": "code",
        "outputId": "cf58f44e-050b-4c4a-d76c-4fe18b5a53c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 2500, TN : 0, FP : 2500, FN : 0\n",
            "Precision 50.0\n",
            "Recall 100.0\n",
            "F1 Score 66.66666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab-part2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiresh12/UMKC/blob/master/CSEE5590%20-%20AI%20Cyber%20Security/LAB2/Source/SameDataDiffModel/lab_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "7a051755-22b0-4122-cbbd-085591184f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "project_path = '/content/gdrive/My Drive/AI Cyber Security/Notebooks/LabPart-2'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "b7b1d0d1-6c5f-482f-bd9d-00b17b790c5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "099dcc97-cfae-4b55-e7bf-0aaf70fa50b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " deer truck  frog horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztfXt8XFW1/3cnHSYdE0LCmDKkxJTc\nlNyUWuivUiq1UCjeUpQqoKKgVVDAq158/fB17w/q44qKclF8gBeQhwhSEIoUBEoBC6UQWmoglMaU\nmDY3bUwbp8mdJk5n9u+PtfZZK51JMnmQJnF/P5985mSdffbZ+5x9zlnvZay18PDw8PCY+Mg71APw\n8PDw8Bgd+Be6h4eHxySBf6F7eHh4TBL4F7qHh4fHJIF/oXt4eHhMEvgXuoeHh8ckgX+he3h4eEwS\njOiFboxZaox53RjzZ2PMV0drUB4eHh4eQ4cZbmCRMSYfwDYAZwLYCeBFAB+21jaM3vA8PDw8PHLF\nlBEcexKAP1trtwOAMeZuAMsB9PtCj0Qi9ogjjhjBKT08PDz+8dDW1tZhrX3rYO1G8kIvB7BD/b8T\nwPyBDjjiiCNw6aWXjuCUHh4eHv94WLly5V9yafemG0WNMZcaY+qMMXWJROLNPp2Hh4fHPyxG8kJv\nBXCM+n860/rAWnuTtXaetXZeJBIZwek8PDw8PAbCSF7oLwKoNsbMMMYcBuACAKtHZ1geHh4eHkPF\nsHXo1toDxpjPAvgDgHwAt1hrXx1qPytXrhzuEP6hcdVVV/X5P+t1PL442IxESwEAxaUVAS3clQIA\ntG/dAAAoq5Dve/OmZEZ3NWfNAAC0vNEW0BKbe/o2KpTNc6+vAQDMe7dIZl3xKB3XLmO78bp7AQDH\nzggBABr+oM7tZL5wxnCAabK56NPTAQCd3dSwuGx6sO/Ed5YTLVwd0FLJGADgsLtkLg5+TQ4POa3J\nLChR2zH+LZ9Kv91qX91++s1cmdkR5eWcTAstzr/a2PdhfgsuP1Aa0CpBa/c8PAcAuD9L/7VZaNvV\ndk+W/bng4Os4FIzEKApr7RoAa0bSh4eHh4fH6GBEL3SP8Y1QgbAm4aIuAEDbq09LA+Z+i5lxPeM9\nC4JdqxLrAQDxrdI8EiauunZWNKDVtb5IG+18TsW2nPSOdwAAyqcL5/9KJ/FI1zNXDgDLlswCAOxp\n20uEzkyuGSG1XcS/VWoqHdRvkkWEymkiFVSUL+KtGQFtZ+vLAIDDMs/kMcZIZ6Hl82/nfqHlypk7\nlJdTL807Uhn79HI6nznzcpQpKjlwuCciG4euXfzc2IbLlY8WfOi/h4eHxySBf6F7eHh4TBJMCpXL\nwhMXAwCqa0SkLjuaTC2xmJhc8iIFAIDmlp0AgJ6UCHH7kyTb7e6MB7SG10jfUBQRAS0ScZYWEsnC\nBfmyr5DE/GRavpOdXWTWSapvZ6SIRLxQAbdXEmFeAbUrDBcEtEBzMkSZM9nUJeNI8baWb3laSf7t\n2Nse7CopoPPHe0WIdPM69m3lMrZzyAi5/hZS0RTIsFFdfSIAoLunMaC1ttUBAM48S4yWVeVzAQBr\nrr2DCDJsQb7adtdBsSNN9XRQZAb9tu+WgRxf9C0AwONbZX7de5sBAEf0EbM9DgXiatuZyjewqkXb\nwivCtAhaejNVKNlQlaZ2zVn26X7Lg7Nqt+pERruDoZepU0J6lYuHh4eHx6hgwnDos6cQG5k4QOxZ\nbbl8TefNJLaz6TD5Pm76H7L4JbeJVa87SV/4pt3EExQUiI9d924yxHWle+Wkid0AgGiFGAHLmQWN\n8G84JN/wnl42wuzeG9A6u+lLHyosCmh5vfRt701Su2RK2OaSIpIoiiIdQovQ/khoiIFZmTaevp9w\nZkwS7Bu25oltwa7k1sz2jU1EjCdkbK0tbFnlKRxXUxPse+GZzTTumNyXfznjFADAjtiBgPb1D9zC\nnfUdV5/zRxXNMWhaYuEUQQm+9Dtb3gh2vb73cQDAspozAtqjmzp5a/gc+rypff/Pz89sk8rCTOp2\nyWT/7UKhTFqajw3lqU6YE3UCZ766Z66ZvlTunPnqBMnuZJ922Ti9LNMbsqFyMLglkI0H/8rFlwAA\ntr4m8YvNbbR4Z88+LqC1bHkGANDYQZJhPEtvy0rERRGdbhYdqgU9ay05jrtj8CZjAs+he3h4eEwS\n+Be6h4eHxyTBuFa5zCsRkfDFjx4k3KVUoq8k+Vb/6EUh/XozNxvJAI5lOT9Pzt3CIl5nG5tyOpQZ\nJNCcqLGyRqakXFQuxVFSq3Q63+kOMQslgnw3oncoKqLrcP55M4c0/OKIiJXxFtZFKKNlYAPi0ycL\ns+xTGqiSYppD+27xE0/t5Ct8JP10qH1rH6ZMEB+69KyANjuffM7/2PSodPw6/zrth75pfE2jMSHF\nKmgce5VZah+P1135iukSRrqlgc61M1IX0HZsJfVSDURUHy6cCiWZRf+Ql5fZTtOyqVUc0lkctPOY\nllQ6GrcV4n2Fqs+U05MoFU1vHh0RishiKAzR/nzuLaXUgIkE0ZKiJQsQzsumiBk+BnpeC0vonp7/\nqfcFtOYEzeHfP7k4oDWytu1Ht10DAKhf+bVg33J+AGoqJWr4+s6NAIDPhk+VPtgZ4HdDncAhhufQ\nPTw8PCYJxjWHrpnfa18jN7dTCsjlcIGyaTgu+IuzhLSUGdx1KuhwF9PWthBXsWGX4geOIhavuFQZ\nHnl3R4vuJIcUwOozGS0nrqI2Khx3VYzOcfhM4jT3JYVTumcTGWITjcLude2i7Qd+JSaaf7vslEGH\ncd/37wy2H11PXOrPbvtxQAtsm86uq6ZZMIOkk542MfekOPfLsYpd7i2m63HMDLr4kajctC9+80MA\ngMp8uVlr95J749onHgtokTN5PM6rUEWnOgmho15I8S7izIv/SWhHsceq4ytbm3YH+zY8SdtFipks\nK6U51OhEIkOE46CzcdIDcd6akw8MlDy2sPKTc93qrpywqBOXJtmdL8XufCG1RN2xacX79vA1TYVE\nwolyh+F8OqK7S/a5sWWbJ/JGJAMPCYuWkFF70WLhpL/3QzaoQzj0Y3gtfOdKrorZIQ9k3S0/AAD8\nYPPGgFZVSGv95hpp9+U62p/Ng3Y8w3PoHh4eHpME/oXu4eHhMUkwrlUus+dK9qW900jl8s47dzJF\nG2OcNU2SbRaxge/EKvEz7u0k9cHxSyh5ZoXy677nPlIBJFQoZdJVWOrOEv8VZmFW+ZejiOTlUFjG\nlswn2ta4yNlxdgq/5PSlAIAXnpREVRfNIfFvg5pLI6tfFtdoB+3BccaSszK26+rFMPjUw5QaFJ3I\nQM9Oulb5ETlneyPRQiGhRafR9p69tG/huxcF+4pZ1VIXF33Jg/eSKOsMbQBQOYNS+jZsYJWSMsQG\nEA1KEFnboS5HbLbbST9aS+ZUSbWnyvUoiXK06yg4EDv7ZDY/9GzQ7QYyqPYwTS0nxNyclR6mh/U7\ncb4wWgkSjdLBeT1CDe2j3+590q40RBc9zfq3XnUP9vJ2kfZv5+2BVEujjSir+h66466A1vjiswCA\n+N5PBLTiUgMA4HAPfOUbVwb7flFEk2n/40MBrYQT+F72rKgBJyo8h+7h4eExSTAoh26MuQXAewC0\nW2uPZ1opgHsAVIJSJXzQWpuFzxsZIkXS5dK5xMXt2U0syk3rxdUvNJ245NmVwtFHuml/c5OwYHH2\n4TqSOZ7aGgk/LGPj3p5ubbHKwnJNcb5nzJp0KwtUJ7EESWU9inN+F4SlXVWskg7No313PijsZBlH\nH37+whMCWnMhSSXxNp3uf3gomK78/w7mhPXnfQ/9pFRum9r3LgQANDavD2jpAuqktobuT0uL5Ev5\n5jU3UR+Ki0uHSNJa8A7Ju3P/L7nQ1UDT05GijktVRroUC1FJXjLpv8q+BafSue64WlL3r2n6EwBg\nzx3ZEqPmhkL2D0zz/U6qpDyOa9eGxGzRoA4uB06vWn4dnM9k9nGyDk+eRZLF5k1iIG9upcmXsDAa\nkzQ5OKaciHV1ssaqWThpVQUj8zja1HHcJSViqA+xhBrWkifPNauh9E1CB7v3btgiUcC1synB7Qsb\nngloZ57NRlO2xUfUuv7iZ74OANhSKRHNn7z8YyMeW/lxlI+ou1uuUbz1xf6av2nIhUP/FYClB9G+\nCmCttbYawFr+38PDw8PjEGJQDt1a+4wxpvIg8nIAp/H2bQCeAvCVURwXAKBF6VnX1JMv22nvouCa\nVEK+fu1x+mLPKZXImMg/Eyf6gy7hMOPMJL/yEulxayLCos6cRp/z9Z2Sh0X8tfSoeEz7s7gvus9j\npbBIkRiNI5oQDumUWSRJPPPIwxldtDNXFu8RpXEeK7nXvS7XowaD46kX/yfYXreVIq02vvZGf82z\nVxqIicthJyd9SSqTQkcXc29sSnhmnbiD7dhNkkWoWEUzFRCrHdJ56Tb3P6QAu7LQ1C3oYIa1nV0e\nC5T730nz5wEAJEckUFVFSvc9WUsX5IZEgthpt0w0B55NJx7sUwE6bpyuvXZb3MNroaVJOj6ulCaq\nuU6n4z7zVOIS580X48LuZpKYOjpk/VWxPaoxvDOgtXIfeZxZNJSWCeTxBHUwk9sdCo1uYNFAWDCf\nCqbMm/OOgHb9j28AAKy6V+xQjkPv5bW5V92MGpbmT3rf+dLx1ygbJzqVb2wGZgdb//XLnwAArvjk\nqf01BgDcuZqetSfXkURbXSVi5qY6evZX3fbTAfsYKoarQ59mrXUrZBf6VHf08PDw8DgUGLFR1Fpr\nAdj+9htjLjXG1Blj6hKJHIJyPDw8PDyGheG6Le42xsSstW3GmBiCipKZsNbeBOAmADj66KP7ffFn\nQ3NKRJTWV0ncT3B444kxESufbSW1yjPrNgW0OYtIKbFQitxjQyMNM85amKeeEPVAajerAPoY5rKl\nq2cR0+WZ0RnwnfEvJKJpgtUOxQXS8e13kHtUu3Ibc3DKiUdXi4jsThU9PMtwBsC3fyriXMMblEo0\nEpF8MJEFpGNp3fBy5sFuZXSICqptHW9XiQolNo2MbmueYEOpeEUGOo4575RCo5s2kiWuJ6SMbovY\nmJ0iI3F1hRi3i48gETkWOyqgzZvHqoV3SL8dXVRv/db7KX/HH5+We/vgwySOp4u+HNB6k7R+lIl4\nyHCqFqd20C58rhBKnvJRTLPKoldZPktKivlYOrgrIeukZx+tv61KRVPDGjNtX3VsUoLz59ZtFWtn\n66uUs+b0d4mSbnEtue1uisrzcvMjpG7oZmcCVfsFB/hkXerZSLCKJnr42EWKPvvc8wCAjnZxlvjp\nDbTGW/dIePHHP3ERAKCyhtZRzbS3ZvRVPM0E24XOmSKLyuXMM68CADz22NVDHu9F55Axfhn/7lIu\nspd8llxot7y8IaA1bpH7MVwMl0NfDWAFb68A8OCIR+Lh4eHhMSLk4rb4G5ABNGqM2QngKgDXAPit\nMeYSAH8B8ME3Y3Ah7f7HHMM964hFWaRYqx3MOG5UHG/dWuJIS1SuiSDHBTNNjSrYIqtBMBvYvQud\nA3EmmVXrBzK3aI889xHfouZSNYW42bLpQysn8MJLYm08nDM8FhWKZFNWQhxu/k6SIlp2ZImyCauk\nIXwBq2ZWBqRl51EOjXt+ew8AoB3KqMyM4qaHGwJSxWzKlPed//hBQKuKkpEu2UsCXBLCPTkDbG9v\npktgokVosXKSPJbOJ043VixBItvbyABV//I9AW3h7GXuSAwXUzlbYYTzoOSrNIqOpjn09t27eS5y\nH7u7ie0tLCSDfr7isZxwWaikwARbqyKKdtfVFwMAPnA55TVJKklu6UIaxxnvE0e15udeAQA8tV5W\nZZyNztFjuH+1KBu47kmzkhTc6UvHUItaXUWc9EMP/CSgac7cob2NJPEFp56cU7+Rgv6jo2668eoh\njLAv3KVp5wCnVXeJu29ZGRG/fOWXAtplF1447HM55OLl8uF+dp3RD93Dw8PD4xDAR4p6eHh4TBKM\n61wuecrh2dU8dL7kdcqdupbFw5hSU7SxSmQ8+9U45cdg6USaDtB1aGoW2rtz6H9qscoNy6GIKVVw\nMsHXtGwaGW3ai0XOLoySCqNmphge8wpITAyF9wS0zfUktkc5BqCPysWhUe5jSxeJnddfLWl8Szjn\nSzJB/bfuFeub84za1aaKanSTRa6G/csB4P0rKGJw1cO303RVDprLvnA9AGD2XFF1nIg5AIAfrrst\nc7w5wqlYnLEzqfydezgZSlr5bvf2ZiapSfH+OFvqtf+6UwREVdnTTaz+mK0CEebNpSIdZ59G+phb\nn5IYhu5Oun6vvCpqL6TpXJU1YphesJjm0ryTa+CqPDkuNCNfuT4czpGkBUMsczsSrLp3FQCgtWXg\nSp933kVpo5dfcE7/jZTGNLE7U0XqcOQIHLLdpXG1bY4pk+fxycfuAwB86rIPDf8EWeA5dA8PD49J\ngnHNoTe3qGQTXFwBXFatNSRWoXyOwjxRhQLWsmviVuVq5XpznI+uuOZMV7oG/Hb+PfwYMZoUVBBr\n1NLOJ2jMtS54JuKDNxkR0vkqQjOPk8SEJDtkOkWcdqKLvuvzTj872Hd4jDjYojzpoyfNskRIRt7J\n029YL26CAdzFVFUCQhF2rXtQR8gNT45q3SlsVnMzSQGRCJ1sy9Ni8LviZWJrr/jWBwLaovdJGbPh\nwnHc7jcvL5M/SivDvuPGdUSp2y4ooBXY3Z1ZWq66QqJ1z38PXdTPffUz0kmE7umF7ye5LZV8Itg1\n5wRiMR+6W4zEH7+Q2p20eH5Amz//eADAlnpyowsXyTp5/wX0YK1dKwbI360mF7v2LALZm4XPf+Vf\nc2q36qF7B22ztVGiqJUHbQaS4f73aTTu/F8AQPX0t2Tsc1cylJZ1vvVF8u+NL5mvWo5c3PEcuoeH\nh8ckgX+he3h4eEwSjGuVS6BmASTV636S8bRHdpNrrmiXn0QibGWz9OHKYxaxwUdlO0WcDaqxI4VW\nw5qW5qSqgN5BUWo1nDp1t1LzFLAmIqzUPM0YPQytvAWAkNzedL5TG8k3vIeNoqk0XatwRBROSY5Z\n7VIXOj9NSqouVew1/heO4ExQat1opRxQVU1G1nhaVDSnLSRxv6JKvGEfq3sdAMB5zND+x3XBvrVr\nrul3el3bpV37bhZs2aqYr7JXpVpIPfCjb4gK7/F1dOy5JXP67T9XuFSyOlI0FUSFCi0SoeusC1y4\nQh9OXRNSUcYx7q+S0y0DwOe+/V3aaJaowrqNlBY4uZeOvW21FG/oqn8KAPD9FlFBrfkDqV9i00SV\nM2Mm3fsOTpdcp6Ku3bgv/7SoeXpZTfbLOzL9wCcCGra9EmznR7IlGKOLX5pj7rH776Ukbx/6iKgt\nK6eV9mmzq03Us63NFCfTsElCq0umepWLh4eHhwdjfHPoqrob9g/eXCeUSf4f4rwu+qgkc9n29FoA\nQHMT8fK6IkeKOanyqHySl7HR6PFHngtoDQ0UVeki9Q5XH9UDzEIft0jOWddEHGODSl9axrlQigpo\nX3FKzLMtW4hD0nUzdrKAEKscwHqTDfpzzck50sovLsRl9JIs76R6hMVMsXExVqFcGdlo87tfC1fR\n9tQDbuQAgA4IVxItJ5esrnzpY2uS2PB5S94W0IrzafvfP0L/d5x9UrBvIA5dw1Wp72jjXCSdijXu\n5Yup5l7/JM3h3POGz6E7rtpx4+Gwkn56+o8knqJYeceRxzkUWheMcPlSfrlKuOXmxvcDAGpqxJ9u\n2btJOlp6Hpf/U30keerfuvYXAa2jg7jq+x+4M6DVbyOO8ZTFFC/4ytamYF+4gMb4kx+Lq2msgtZ4\nZcUY1qAbRXR3C7e8syWblFGRhdYXt9+9Otj+/QPEoX/qkx/orznWPydFOFzOnPa9Mo6CyNAiwbPB\nc+geHh4ekwT+he7h4eExSTCuVS6xMhHf29nkmWrPIpbwLIpVdZ3fPkEGsB3/IxbKKy4kFcBF5awn\nUalK6+tfBSCVWOgf+onGRK9yFEfevU4Sap/Ivjw+fXu+iKFVNUScWyomzTPPmgUA6NxLBt43GmQc\nO4qI9uhzIvI60bsxWzbfHJFiWT6lDLy9CeowHqdrO03NJZyidtUlksr29+xr3v72hQHttB9SFOZL\n95Gh7ZbvSAyrqgmTgQ/cJ9suz9laLqBzZsURqqWrPTpApSUASadi4VDiIlX6pyuP1GhlhaLayo8M\nUX2VBS7lbTRK66NHWUALCvh6ZykkqqNHXerdvLxMI6rLo1as7vtTW2h+W16V63HPvbRdVXkHAOB0\nFU8QqyCrfec6MQgXc0Gt915wkbTj0NPEJkqlfOFFK4J9jVu3AADWPCxplk9ZSGq0YyvHbyx2MvE3\nAEAockTGPl3xqQDZVB2kEtnL0ytVqtUNzz0NALjnjtsD2vpnKAFca/O2gFY6++0AgKY3qMDt9iZR\n7SQ5NXc0KuswlR55ZIrn0D08PDwmCcY1hx6HMrgwl4Up/DVVqTzddnyHhK25b13TG5LXor6ZDJPL\nF1N+kvculjqBkRnEoTz1mHDGcfbZa2iVr+iOOH2qNzmT6j7htiLs+litvuatLcT5l5UJF1A2lzj0\nhi1kxl1196vBvlSYztWtfNv2seEslBwai+7cEQmcd0QxIz29rlp9us//AJDn2qn2294gLu9dV/x7\nQDubak2gppI489NyHFvdM1LP8oz3EcvoeOoa7Z95VCX97srGoYvVvLK4GgCw9w0yPB2uls4UTh1c\nqtKkJtIjN0AFEaJ8mfcn5P64whU6fa7LSxNSRtECliQSbAUPFci40ryOWpRUGvDZev0zNnNo8z3b\npVatc0Sdc6wsynaWMhctfjSgXf2Ny6lbrpNaWCCG7OIIGbLPP0fWejRKkmckvSVzIOMEX/oCpab9\n8Y03Z+yr3yTPXEuWcNcYJ2C58QYyyv/LqWI8v/YaSv385KMb1BF03b7zzasCyt33/g4A0M4OEbqu\nq7ujx59QHdCqqkdSboXgOXQPDw+PSYJcClwcA+B2UCFoC+Ama+31xphSAPcAqATFz3zQWtvZXz/D\nQaJbQoXyOUtgqCjT0z9UzMUBwrJvCrcvjSrnfi46cPtzxOf87DHJQBctJo7qzJnyJa6aTrS5MdEj\np58jrnorl5cvO1KCcfKL6bvb1iXj6EgRN96yXfSPKz7HCmRmSfOjwmnm5bErYVy4BtfbMdO0H+fg\n6MOE8qc72SfNHG3vY71z+u+yKxzh7IkhyQV59hKSaI5KiIPozvXkPtf0KuXGuLZCOMHlZ5Hu8jg1\njF9xjv9oSOZ3/nzi0NtYxdgyXdpX1tA/vQVSYf3Cs5cDAKZVSDm9ELtZLjub9MdPrRUudePzFESk\n9aZ72wfLcTk4nPthPt8zpw8HhDPPVvQi1Mdtkbad/j2cpyUzui8qo9GAyOYo6e7U49tF133GcXTO\nBQvF3vHsc8RtvveyfwMAbL1PgraOrSCJNtmrbBAhluaS/btnHmo8/sRj/e578olnMmixw0USnzOX\nJPZvfmclAOB731LBdN3oF/eseiDY/hiXPjx+zmlEUM9jkKenWtwjl51F9yOL8JUzcuHQDwD4krW2\nFsDJAD5jjKkF8FUAa6211QDW8v8eHh4eHocIg77QrbVt1tpNvN0F4DVQ+d/lAFwy6dsAjDx9nYeH\nh4fHsDEko6gxphLAiQA2AphmrXVa/l0glcyooqxY1CVOXHWRjtodrIjVJZEileqVIyN7lUjIqUuQ\nyKf2HXtFpdPRQlM5vkxUKFGOGs1TOWWan6XUpE6xkN4jonvzHuo30adkxQAiKbuohXpEnEs5uUx5\ng7EHITq7dLaawaHnHmLRX5tVe1l2PKqMXNsqZ4iBpjVO2rOGLWLIifA1bdok6UmjFaSGmVZKRrTO\nJpn7T66jKLjNqgp9MWsUCvLEP+/ZW/hcz5Ga5LP1kmcj8YpLBSuqnIZ6Mh41dkiUXfl0El1r2f3u\nuBpRnZUV0klLVKKeEKeH3b93+CqDA2yk7mRjqM7l0ttDNzCp9F5uDfeq++3s3M5e29UlN75jFPMr\n6ywh37/mRwCAObPFCLd9J0VRN657EQBQXiVqxs4OygPzi+vlvl9yMdWSnTtXKm1IBdvxgeqZtJ71\nHQ4UWspAXnF4fka7Rx96pE9fg7kj5IfpXTVvrjha3P4rqmF7910UPbpovlTtvP8huqZJ9YwuX0Iq\nl/ueENfHoSJno6gxphDAfQA+b63dp/dZay1Iv57tuEuNMXXGmDpn5ffw8PDwGH3kxKEbY0Kgl/mv\nrbX3M3m3MSZmrW0zxsTQN5VKAGvtTQBuAoCjjz4660u/PyTzJDgkkaJvz/6ezHJfnb3E4aXVCHoc\np9OmXJJysDYkVFGNpk7a3vyquD6G+BO4KEYGubWt8jVNDPodJ9TMIe4wD86NTdwFu9mFsFXZfnt4\nXh25Wsfccbt3ybYLdkoI2+eq0VUspoCrenX9WrcRpx0NiSGsK0600jJxaZuzkAxmm9dRrpCGhyU/\nSFfxmbTRLOOInkKl4jqelbwgp5xGOXNSm8hQldgn11sg435hK7mcVSkrZ1GUuM19LMSce64EzRxV\nRMcWR2Xc+SEy2F599dVZzpUbpnJwUs9euu+FhXLTQrxQErpgBa9ZzaE7O2qEDfqLT5WCB1fdn6Vo\nyBDhzOiXLRejciRE/Hp+sXDh1WFai7/4Kbn41VaJf8Oi95L0s/Q8uX6RUuJIUwValBx8PKEgUAxI\nT6FjS5S3XseOvvc+NEUs5MkDdIKisDwvYTZIpxRvOrOGOjyuhqSH1jZxka2IUX/lMZlLWZikudZ2\nWWOtTey+HAiScm/zS+h6pDql36994ysAgEtWyLqby9Lid79Da/30JXIPOuIkhW7eJG6fZ7xTF7sY\nHgbl0I0xBsDNAF6z1v5I7VoNwIWTrQDw4IhH4+Hh4eExbOTCoZ8C4KMA6o0xzvfu6wCuAfBbY8wl\nAP4C4INvzhA9PDw8PHLBoC90a+16AKaf3Wf0Qx8VdLYqHYPLV+vEOp1n1EGpaNCbJaJ0ADjRdG6p\nCC0de8kgOGemGFDCLG5t2OTSxeaG8mMl/LG2lsS+UD7pB/JUvtNOlsYLC5XBtphE00RiiNGNCfEl\ndtUxystELm5tIDFyw50uPbAP/GqaAAAVRElEQVS+ptQuW8XUThXB27TmJ7xFapAzy0V+bj97CQCg\ncmZtQOvtoCvW3LY+oFVPp2MqS8nQVhs9Svpgn/6bf/PDgHbhClIRxarED70sdiwAYEcLqQpqZ75V\njVhvjx5cTha2dSIel2tbzDEJWg3hIkmn9DGeul9quGjJ0mBfPqtcRuLp7ZQ7Dz78dEDbw/egskKq\ns4RLSbfw4L3UrkRF6y666FoAwIKPfEKI/Gi2r5aIS4gWo18kdU4efjY7dgzQ/sDODFqXyneTzU1g\n42ZatcfNpAFF1PV2cRjPrFsb0PK66Cq1DviuUKqzzsyo5brnyY//W/9xZUDrZZvh11deAQBY/dsn\ng32xGF37NatlHNFgoLra8dDgI0U9PDw8JgnGdS4XROSrWMCGkDCzQ3n58i06wMamRI+qsJ7IYqB0\nh3AfBSkx6Lyfmb1CqHwLbAdpaRLOeE275HoZCmKl4lJZfBj9htmoFlYcRBGfKlqk8o7EqJ0rV5Yz\nkop/Ya5mdpVEpiWYk8kW3ltdTheksTWbC5WWFIhDKwK1/9zV3wv2NC+g0ITv/Vzc3ZJcB7AzLWzW\nGvbdm/dOKtAQSoqT3UPf/2nG2T/EBR1uf0CiQTespyIQFbNoX4uaekWWANv1T7ycSRwiutkPdiqX\nMEvsl/uTZnfFiPIX7OHLVhkTD9+qanKtO/Ms4sxPPnVxsC+FlSMeo7tTjYr7bHyWuepnX81oH0AZ\nyL958ZcBAB+/4J3SRyNHse6W1ZOfA4c+lijk+x6NimH1oYcpSjsRl/dDOIuwP1Q01nMRkpT06ySg\nhu30nG3YKBJzgsWM+x+Xe1C3kbYv+oLkgxkqPIfu4eHhMUngX+geHh4ekwTjWuUSjYpoGmKjaIrD\nJrtV4q6EK1ShNRJOwyHBgQhxRGk0RILoSUoUj/GxbcrKWcCGoX2jELGnkzR1pcg3PtFFHYdSoo7J\n42+sytGECKdUDWXmJRsYs9U2z6utTeTi9FTe2J9p+jz3AipPcf11twa0nnRbRjuHLq6nueplUdHc\nftnJfCKdYtUZfORCbwiRmqE5QRNMKtfmUDGPV+mFinktbHj6hYC2pZHGdm6UVEpx1UcPa3e+dOXV\nAe3Xd5OX7eevXN7vnAaDC1bu5khibSBnG2NwbkA86c+dOzegnfZuUrWUTCPD8HU3ZKZ6PRTQGYyd\nquihR6W27kUf+jwAoDX+ekDbPhYDywFFvMR27KxniqhBXtlEqhHNyY6CxgURjjyt2yDGfqdqcfjD\nIw8F28dWzsbBaNqXQRoyPIfu4eHhMUkwrjn0BU3issQVugKHOZWKAYVseAopjrubt1OFqmGI2KUQ\nG0yjinuKOIZfccFh7vdd84T49l4ayP4U9RtXroR7WVBoVozsLv78h0OaD3D5aJjzVkZAx4WH8pXh\nkY/tDQ3NKPqvt6hxMJO84UZVwKMe/eJ7P/zPIZ0LSbqYs+dLeTr89CtZGmYaqyvLiau+e/XPAGSv\nt37Wko8F2/VNZLF7vVlEp/kLTwMA3H8DuTfe/+Nr5GA2wNbMEYPj/7vhJgDAvhYxrA4VOncLAMxQ\na8dx70m1xirYq/brd6o8IXf2zRkyXnDuaeIS+p93fQ4AsOr7siYaOD/P1teECz1s1kljNDqBkzdj\nR8ozVOacCHaSWNf88qZgX4hfEjVVErHa+Qa5IapKk2hkbjnXkjJlZdRv0zZ5qMr5frt0LdXlIvcc\nO0OpDkYRnkP38PDwmCTwL3QPDw+PSYJxrXJZpERal+m2m/1pdd7GMEve1coP1vn/6iRe+zpo2+Xt\n6laVR3rYkNKjxGaX2jQVku9et0t3yql9IwV9yocDAJrbMmsHRvJFXVIa1I2k3ykpUceE0tSfcrNH\nHp+/OKQiYXPA86pgy172K+4plCtXUEFG557tTi8wtJqlfZAmsfX/fuyUIR+67DzyV8+manH48MWX\nBtvNXJsxVCKpjk9aSKqejWtvyuz/om9THysk0nHxkqMBAL+8evgql97evv+rjM6BOkbfMrcUa9W9\nbRgNi9ybgGNnSRTpZeeQyuULnz0voBVHyLB73eUSY/CVWecP2m+tCoJ0azysQjkbdrH/Pv8fVVXI\nXAxKWbHoRoo4iCOl0hS3NlGCrypOjtXYKGrG3duoStmF530ooK353V0AgERc1EdlrB0pmUbPSDwh\nThitLZwaWd3b899PQfOhXnmpzK2id0SY68bWvk1eUNUzqd+lc0T1k0xkS0o3NHgO3cPDw2OSYFxz\n6C0q822SOXMXwKZdxIp5X4FybatkbjmuIt46+QPIGWqRUJ+zBDMJOkXMFN5/QBkoO3lMqTh3FhJu\nYR9zbK2qD8e0FRdKu6kcmpZmlj4vnRlOqDkOF7Kaj6H5Lb6xWrY7+Tp8YsU5Ae2We1cBkHwYO3ZL\nduOjplH6nuYWKTTa2kaGMC31dMdJPEpwat3KSsnl8smLP0PHvS7ubpjCHMkB4YaS8cElg499RIyt\nb59PnGDXDhFBHn2EOJ5zP0F5R058h0gKNbPJRey0hW8JaKMR1Jjg+x3mp6hbRWO6Qh4pdRvd3SvQ\ngtb+wc+jXQizMfRDK3uSG8or5KwxTjVbEBb2unEbSUlDlemKlRQTYza4rU2M267ESlFwKjkgyVxy\nUVQe3Dg/1N1KZC/gC33srBMAACHF5TevuwMAcPaXJBrzJc4J9IYqxJLkqOztL1P/eerCx/jShEvF\nC+PECpIvNz8tbot5nMsl6UR9FbldVsKSRZe85CLZ8lMNEZ5D9/Dw8JgkGNccevcA2c80k+M0cBGl\nn3OMkU5Q6FK9ZNuX4A9lvmKWnZdgl2rXvOegPpQ2P1tmQocji+VrXpRPA0ky+5aXJ1xIPhdtSCUP\n8okDkD/EwKI5b5WE+UUziMu6csU1Ge3cyFoaJQCodhpxN6UVhwW0zesbAQCXfESqxQ+E9Y9RJrkZ\nb5sa0H54I+m4X69vCGgd7Vlro/TBnfcKl1//wn0Z++fMooyOl3/6cgBAYbFw43PZAy/zio4MLgFo\nnDl1neHGZQTU5wzWjOLKq/gJbMqy1kv4t1QuXyAV3PHrawPakg9/eQijFnxuxUeC7WVn01pZxAVL\nIqroRM9OKgDR3S4L8KEbqLza/CF635WoNZzH0l1M4uoQYu43wosyrqR0VwkylBSO3uVBKiyRdiF+\niC/6KBWbaNgmboul3McDt/1XQGuMU/uEypZ5pLOB8NhK9I1kNri2Rko2TmM7QP36ZwLanmbmzPn+\nNby0Idg3ZzYVF5k3W4qMvLBWxjlceA7dw8PDY5LAv9A9PDw8JgkGVbkYYwoAPAPSckwBsMpae5Ux\nZgaAu0HZUl4C8FFr7d/772no0GKUs8Nx6cM+oqyra6EyeYKLrkMV1Q5E3gP8GevWbmesrilQ4h9L\nhH0S6rsvoDNv7BlwBkAxj623SL6de1NEDKXppBEVcpjHUaF5BZn6FU3JxXxyz8+eD7ZLXDTtAO2X\nLjxhwP4WzD4uh7MKKisKMmgVpaT6aVRG396eZJ82t94lxRiu+Cy5zKWUa+cNN68BAHzm4rOGNJ5R\nB6+t2OH0q9Mgd/Ba1DNzZV37ZPPlZVHjIoqV2rCNoxW7lIrGOcX9SEVt1vJz4mxvxWocTkWj13qM\n2y+dJ66JiY6tAICGl8m4nacy6yY5OvoPD4vK4JcPUoNKpQ7KBTq6NlBnKDdEl+c5xBdzaliu4DHs\nvlugUkvnsStjMiG0ojAZyLc+9wQA4KHHfhPsc6mB9nWJ2qacn7mUujFlJfwPv0DSSVl/3ey7XKpS\nYt96C6V53tUmroclh/edZ6JDjKIbniR32aQyhFZUZcnzPETkwqH3AjjdWjsHwAkAlhpjTgbwPQDX\nWWv/CZQ66ZIRj8bDw8PDY9jIpQSdhTAGIf6zAE4H4KwqtwG4GsDPR3NwKkEh2Dc/CDhIq33u49mu\ncqikHdeigocclxLhWWdLzqgLEsQH8AdzwsBgblsh5lKbFGtygFm1QnZIK0zKlz7NhtJUfra8LcKj\nD8xLEwqV5bhu0/8CANY+9nhA++43yYCY2O+4Cpl8JEyszOzaWQEtzP52aeWLV8YZMUuKiR0pUVzL\n889lJospZi6rV1m7bmUD1c03uTJz4pQ6b8EHAACP/OG3AS06ckZmVOA8Vp0Ep+qroKgks727o2El\nuDhXVFe8REuUM7gSn84A6ua+Q/v0Bn0RulXWPrc+C9WTXs+L9+zP/SCg3X0tZU88Z9m3AAARxXm7\n8abVYnePVTwHt0uNB3U1FbfdmsjSMtv6dzQt92Q7ll8Ej+daxCTLg948uDPonbc9N2gbAECWLIoP\nrenfheKq9+XWbTbkpEM3xuRzgeh2AI8DaALwN2uts83vBFDez7GXGmPqjDF1iUS2i+/h4eHhMRrI\n6YVurU1Za08AMB3ASQBqcj2BtfYma+08a+28iGZ/PTw8PDxGFUPyQ7fW/s0Ysw7AAgBHGGOmMJc+\nHUEd8NGD9rvOY41FxEXgaeMKS2A6b4aTftM6l0Zv32P158VJwXk6ay2361VipfOYzlXWKKwgX9V2\nlds3ke8iPwlhZap0BpT0ILXec1G5fPqL4nPe8hdSq/QmxDqW2H/wLOT/RC+JhK6C+mihftNmAEBP\nl9KFufNOIRXUjf8taqFLVywZ1fOPJuIsSrtI0U5leAx1Z7YP2CelmglPpfucyKa6cP2p9i6lSJFW\nO/FScX3olePWWEL5uTtRWucLuva7vwAgKhrtd13EtW/3qsCNMj5LNItqyePQYVAO3RjzVmPMEbw9\nFcCZAF4DsA6Ay8azAsCDb9YgPTw8PDwGRy4cegzAbcaYfNAH4LfW2t8bYxoA3G2M+TaAzQBGvXaW\nShmCsPv0MPuRVmzIVOZqy3SCjiwMrmt3gPvVLoqF7C7WqZjWvcyBaWYrl2p01dXC+y98BxkNk4XK\nosRsk/PIiqg0fZEizu/SJ7MiHZDW6fxyGEhNpVyQfM4jkegS1i4+hzLENWx5YPDORglf+n+fAgBE\njpQo1vMvorwaP7iOfiujZszGMxI4o33aFSVRXLBbutpozgHCfVxHe5irdsy4vutOotQuqi6nSIcy\nLgbj4P/10u/NQqtgg+fSs6XgRxfbt6oTJIN2dIhk1t7OBWFiIjKneXd8FMozeowecvFy+ROAE7PQ\nt4P06R4eHh4e4wA+UtTDw8NjkmBcJ+fSYqWLuHTReAmlBwmxuiSi8ow639l8JcMWupS6LAdrcbGd\nz6Wrxc+bRyebPksMc/c/QQl0wsVkDZpROS3Yd/pZ8+i4U2sDWhGPaVtTXUAr5bDNYt5ZqAaeYqtX\nQZ4I5uECUpPotLXX3JLph3wwvv7FTw3aZuxBc0jskTSjq+5cz78rx3w0V1111eCN+kHyoIhjbWLO\npkI5OMoYEGO8U4loN21JAJcJHTXs1DDZoofdObWap5XVPF2qwksoQg+FK+xQ9c9SbqSL1+Se3dI+\nzomsvN/a+ILn0D08PDwmCQwFgo4Njj76aHvppZcO3tDDw8PDI8DKlStfstbOG6yd59A9PDw8Jgn8\nC93Dw8NjksC/0D08PDwmCfwL3cPDw2OSYEyNosaYvwL4X+j8qBMTUUzsOUz08QMTfw4TffzAxJ/D\nRBr/26y1bx2s0Zi+0AHAGFOXi7V2PGOiz2Gijx+Y+HOY6OMHJv4cJvr4s8GrXDw8PDwmCfwL3cPD\nw2OS4FC80G86BOccbUz0OUz08QMTfw4TffzAxJ/DRB9/BsZch+7h4eHh8ebAq1w8PDw8JgnG9IVu\njFlqjHndGPNnY8xXx/Lcw4Ex5hhjzDpjTIMx5lVjzBVMLzXGPG6MaeTfcV2Ii4t8bzbG/J7/n2GM\n2cj34R5jzGGHeowDwRhzhDFmlTFmqzHmNWPMggl4D77Aa+gVY8xvjDEF4/k+GGNuMca0G2NeUbSs\n19wQfszz+JMxZu6hG7mgnzn8gNfRn4wxv3PV2Hjf13gOrxtj/uXQjHpkGLMXOlc8+imAswDUAviw\nMaZ24KMOOQ4A+JK1thbAyQA+w2P+KoC11tpqAGv5//GMK0BlAx2+B+A6a+0/gTK2XnJIRpU7rgfw\nqLW2BsAc0FwmzD0wxpQD+DcA86y1x4Oy316A8X0ffgVg6UG0/q75WQCq+e9SAD8fozEOhl8hcw6P\nAzjeWvt2ANsAfA0A+Lm+AMAsPuZn/M6aUBhLDv0kAH+21m631v4dwN0Alo/h+YcMa22btXYTb3eB\nXiTloHHfxs1uA/C+QzPCwWGMmQ7gbAD/zf8bAKcDWMVNxvv4iwEsApc4tNb+3Vr7N0yge8CYAmCq\nMWYKKI14G8bxfbDWPgPg4KT7/V3z5QBut4TnQQXkY2Mz0v6RbQ7W2se4sD0APA8qcA/QHO621vZa\na98A8GdMwIpsY/lCLwewQ/2/E1KAfNzDGFMJKsW3EcA0a20b79oFYFo/h40H/BeAKyH1D44E8De1\nqMf7fZgB4K8AbmW10X8bY96CCXQPrLWtAK4F0AJ6kccBvISJdR+A/q/5RH22LwbwCG9P1Dn0gTeK\n5gBjTCGA+wB83lq7T++z5CY0Ll2FjDHvAdBurX3pUI9lBJgCYC6An1trTwSljuijXhnP9wAAWNe8\nHPRxOhrAW5CpCphQGO/XfDAYY74BUqn++lCPZTQxli/0VgDHqP+nM21cwxgTAr3Mf22tvZ/Ju51I\nyb/th2p8g+AUAOcYY5pBKq7TQfroI1j0B8b/fdgJYKe1diP/vwr0gp8o9wAAlgB4w1r7V2ttEsD9\noHszke4D0P81n1DPtjHm4wDeA+BCK37bE2oO/WEsX+gvAqhmy/5hIAPE6jE8/5DB+uabAbxmrf2R\n2rUawAreXgHgwbEeWy6w1n7NWjvdWlsJut5PWmsvBLAOwPncbNyOHwCstbsA7DDGHMekMwA0YILc\nA0YLgJONMRFeU24OE+Y+MPq75qsBfIy9XU4GEFeqmXEFY8xSkAryHGutLte6GsAFxpiwMWYGyMD7\nwqEY44hgrR2zPwDLQJblJgDfGMtzD3O8C0Fi5Z8AvMx/y0B66LUAGgE8AaD0UI81h7mcBuD3vH0s\naLH+GcC9AMKHenyDjP0EAHV8Hx4AUDLR7gGAlQC2AngFwB2g+tHj9j4A+A1I358ESUmX9HfNARiQ\nB1sTgHqQN894ncOfQbpy9zz/QrX/Bs/hdQBnHerxD+fPR4p6eHh4TBJ4o6iHh4fHJIF/oXt4eHhM\nEvgXuoeHh8ckgX+he3h4eEwS+Be6h4eHxySBf6F7eHh4TBL4F7qHh4fHJIF/oXt4eHhMEvx/EaRH\nPhDsJV8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "81512a50-34f7-4ec3-df05-6ff8f21f5fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2m0DwoK5Xt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yAlGMwn5f78",
        "colab_type": "text"
      },
      "source": [
        "Below is the preTrained Target Model loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0kU2-iVzcnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbLKKajm5eUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the model\n",
        "load_target_model = load_checkpoint('/content/gdrive/My Drive/AI Cyber Security/Notebooks/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Target model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD6Yc_R44QCX",
        "colab_type": "text"
      },
      "source": [
        "Below is Shadow Model Architecture different from target model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygSJAmC94UjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# Shadow Model Architecture\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class shadow(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(shadow, self).__init__()\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(3*32*32, 2304),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(2304, 1536),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1536, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 768),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlOhiXBHLV0H",
        "colab_type": "code",
        "outputId": "cfc0f7af-9de3-43da-bae5-0c2ed29054cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "117a868a-6883-482b-8d9d-89bd186f3b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "shadow_model = shadow()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.003) # ADAM \n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 2.267785725879669\n",
            "\n",
            "Epoch : 2/20.. Training loss: 2.231721895980835\n",
            "\n",
            "Epoch : 3/20.. Training loss: 2.1984924865722655\n",
            "\n",
            "Epoch : 4/20.. Training loss: 2.266147186088562\n",
            "\n",
            "Epoch : 5/20.. Training loss: 2.2930209539413453\n",
            "\n",
            "Epoch : 6/20.. Training loss: 2.2960329275131226\n",
            "\n",
            "Epoch : 7/20.. Training loss: 2.288782145690918\n",
            "\n",
            "Epoch : 8/20.. Training loss: 2.287959258651733\n",
            "\n",
            "Epoch : 9/20.. Training loss: 2.284956303215027\n",
            "\n",
            "Epoch : 10/20.. Training loss: 2.284158215522766\n",
            "\n",
            "Epoch : 11/20.. Training loss: 2.2853016677856446\n",
            "\n",
            "Epoch : 12/20.. Training loss: 2.2865737369537356\n",
            "\n",
            "Epoch : 13/20.. Training loss: 2.289488263320923\n",
            "\n",
            "Epoch : 14/20.. Training loss: 2.291618667602539\n",
            "\n",
            "Epoch : 15/20.. Training loss: 2.292216255569458\n",
            "\n",
            "Epoch : 16/20.. Training loss: 2.2943381776809693\n",
            "\n",
            "Epoch : 17/20.. Training loss: 2.2889133386611937\n",
            "\n",
            "Epoch : 18/20.. Training loss: 2.2840758975982665\n",
            "\n",
            "Epoch : 19/20.. Training loss: 2.277169578075409\n",
            "\n",
            "Epoch : 20/20.. Training loss: 2.294704028892517\n",
            "Our model: \n",
            "\n",
            " shadow(\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Linear(in_features=3072, out_features=2304, bias=True)\n",
            "    (1): ReLU(inplace)\n",
            "    (2): Linear(in_features=2304, out_features=1536, bias=True)\n",
            "    (3): ReLU(inplace)\n",
            "    (4): Linear(in_features=1536, out_features=1024, bias=True)\n",
            "    (5): ReLU(inplace)\n",
            "    (6): Dropout(p=0.1)\n",
            "    (7): ReLU(inplace)\n",
            "    (8): Linear(in_features=1024, out_features=768, bias=True)\n",
            "    (9): ReLU(inplace)\n",
            "    (10): Linear(in_features=768, out_features=512, bias=True)\n",
            "    (11): ReLU(inplace)\n",
            "    (12): Dropout(p=0.1)\n",
            "    (13): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (14): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHZNbnkgRCZ0",
        "colab_type": "code",
        "outputId": "e4ce492d-668a-4b00-e798-134452c35d6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the {len(shadow_out_loader)*batch_size} test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 10 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAIYt1goU0VS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating dataset for attack model\n",
        "batch_size = 1\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "94e9f94e-5559-4557-8ded-aa7d0b13c57e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint('/content/gdrive/My Drive/AI Cyber Security/Notebooks/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000]) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([2.0827779e-03, 9.1434194e-06, 1.1376935e-03, 1.1234281e-05,\n",
            "       5.4429383e-05, 7.5347657e-07, 8.9491208e-05, 1.0409669e-05,\n",
            "       9.9652940e-01, 7.4574658e-05], dtype=float32), 1]\n",
            "[array([9.47831154e-01, 1.95769167e-06, 1.10436315e-02, 2.29043979e-03,\n",
            "       3.72032225e-02, 3.95336610e-05, 1.03994797e-03, 5.94004487e-05,\n",
            "       1.15450195e-04, 3.75188305e-04], dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFRCL63ZqkRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J1B1OhMp6er",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "    \n",
        "# make predictions on both datasets (target_in and target_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffqsLQIn5ru_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reVyW6wB1TyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRGOHNTq1ag-",
        "colab_type": "code",
        "outputId": "7c91a6d8-1f5e-4e28-eaef-ddd97b5747e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNqPwzXE1aVt",
        "colab_type": "code",
        "outputId": "9f2b3f53-742c-4643-893b-3dfa86af0801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06933453347682952\n",
            "Training loss: 0.0693402024269104\n",
            "Training loss: 0.06933072944641114\n",
            "Training loss: 0.06931664196491241\n",
            "Training loss: 0.0693239943575859\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kfc8ypq1kzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnh8iA1d1oPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO9g7SVH1srQ",
        "colab_type": "code",
        "outputId": "406c8ddd-9054-46cb-9b3d-96749df2a528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 3473, TN : 2588, FP : 3162, FN : 2777\n",
            "Precision 52.34363225320271\n",
            "Recall 55.568\n",
            "F1 Score 53.90764454792394\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
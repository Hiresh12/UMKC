{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP10Membership Attack - solution guidelines.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiresh12/UMKC/blob/master/CSEE5590%20-%20AI%20Cyber%20Security/ICP66/Source/ICP10Membership_Attack_solution_guidelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvK6LaVhrfZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# required imports\n",
        "import sys \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "import torch\n",
        "import torchvision \n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05dkTKAsEh-",
        "colab_type": "code",
        "outputId": "012d6988-d86a-4f90-d42c-88156327c288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# mount the google drive to download the datasets\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "project_path = '/content/gdrive/My Drive/AI Cyber Security/Notebooks'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEW1mLverl7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create transforms to load the images, nothing much is needed here. \n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalize the test set same as training set without augmentation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjsFJTFwr1wV",
        "colab_type": "code",
        "outputId": "652b4523-cf04-4c51-e619-221f05f93df6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# download CIFAR 10 training set\n",
        "trainset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# load the trainning set\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "\n",
        "# download the test data\n",
        "testset = torchvision.datasets.CIFAR10(root= project_path+'/data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "\n",
        "# load the test data\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "# check those manually on the dataset site: https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itY7G_y3tDnC",
        "colab_type": "code",
        "outputId": "89f1a88f-d794-4c8a-ade4-5645bbf018ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# helper function to unnormalize and plot image \n",
        "def imshow(img):\n",
        "    img = np.array(img)\n",
        "    img = img / 2 + 0.5\n",
        "    img = np.moveaxis(img, 0, -1)\n",
        "    plt.imshow(img)\n",
        "    \n",
        "# display sample from dataset \n",
        "imgs, labels = iter(trainloader).next()\n",
        "imshow(torchvision.utils.make_grid(imgs)) \n",
        "\n",
        "# notice who we converted the class idx to labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# run this cell multiple times and notice diff images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "plane  ship   car horse\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL3QHBweHMoF7oTs4ODiUCf4Piyq8qxQvG1cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJK32k42gbEK",
        "colab_type": "code",
        "outputId": "c3ec1b3f-90d4-4d3b-d076-b60615c7089a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# divide the training dataset into the required groups Make sure they are balanced\n",
        "# original trainset is made of 50k images\n",
        "\n",
        "total_size = len(trainset)\n",
        "split1 = total_size // 4\n",
        "split2 = split1 * 2\n",
        "split3 = split1 * 3\n",
        "\n",
        "print(total_size, split1, split2, split3)\n",
        "\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "shadow_train_idx = indices[:split1]\n",
        "shadow_out_idx = indices[split1:split2]\n",
        "\n",
        "# two groups to train the Target (in and out)\n",
        "target_train_idx = indices[split2:split3]\n",
        "target_out_idx =  indices[split3:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000 12500 25000 37500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4wJ_0lkhp76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9LuQJNuCXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# create a CNN\n",
        "# Input shape (3, 32, 32) \n",
        "# architecture: simple. 2 conv and 2 Max pool, followed by 2 fc (120, 84) \n",
        "# output of fc is 10 because we have 10 classes!\n",
        "\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    \"\"\"CNN.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv Layer block 3\n",
        "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.LogSoftmax(dim=1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Perform forward.\"\"\"\n",
        "        \n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)\n",
        "        \n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99Eu3OsavI0t",
        "colab_type": "code",
        "outputId": "717a5274-b19b-4833-e386-b3df03cab299",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# check if CUDA available or not\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER_B4V8YjKyU",
        "colab_type": "code",
        "outputId": "6439ceb7-f7a8-4c10-c957-b4ae34b171ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a target model and train it\n",
        "\n",
        "target_model = CNN()\n",
        "taget_model = target_model.cuda()\n",
        "criterion = nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "optimizer = optim.Adam(target_model.parameters(), lr=0.0003) # try Adam VS SGD\n",
        "\n",
        "    \n",
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        logits = target_model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(target_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Model: \\n\\n\", target_model, '\\n')\n",
        "torch.save(target_model.state_dict(), project_path+'/target_checkpoint.pth')\n",
        "        \n",
        "       \n",
        "        \n",
        "        \n",
        "\n",
        "print('Finished Training the Target model...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.815010720659095\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.5021809918801192\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3114420452995983\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1729637138983782\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.06848800327162\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9960794977443602\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.916956645105501\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8589054951277535\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7988187772081331\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.7568713392671722\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.7210794835901626\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6762751019500253\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6431123682528811\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.6169754425659204\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5832670197329101\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5466347385455123\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.5364264194446299\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.5024691348314247\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4862018297414493\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.46013908436440903\n",
            "Model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Target model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY8ktdskRQN",
        "colab_type": "code",
        "outputId": "a3b6c9c3-685b-4024-bb64-b5238ff1e613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Target Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = target_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 77 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEClKFqikmUl",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha_VqRVVkoCm",
        "colab_type": "code",
        "outputId": "da5617af-a99e-4b2e-e377-19de6cf4c628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# initalize a Shadow Model and Train it\n",
        "# for the first ICP, your shadow model can have the same CNN architecture and hyperparameters\n",
        "\n",
        "shadow_model = CNN()\n",
        "# clear the cache\n",
        "torch.cuda.empty_cache()\n",
        "#send to GPU\n",
        "shadow_model = shadow_model.cuda()\n",
        "shadow_criterion =  nn.CrossEntropyLoss() # CrossEntropyLoss\n",
        "shadow_optimizer = optim.Adam(shadow_model.parameters(), lr=0.0003) # ADAM \n",
        "\n",
        "\n",
        "# let the magic begin\n",
        "epochs = 20\n",
        "with torch.set_grad_enabled(True):\n",
        "  for e in range(epochs):\n",
        "      running_loss = 0\n",
        "      for images, labels in shadow_train_loader:\n",
        "          # sending tensors to GPU\n",
        "          images = images.cuda()\n",
        "          labels = labels.cuda()\n",
        "          shadow_optimizer.zero_grad()\n",
        "          logits = shadow_model(images)\n",
        "          shadow_loss = shadow_criterion(logits, labels)\n",
        "          shadow_loss.backward()\n",
        "          shadow_optimizer.step()\n",
        "\n",
        "\n",
        "          running_loss += shadow_loss.item()\n",
        "      else:\n",
        "          print(\"\\nEpoch : {}/{}..\".format(e+1,epochs),f\"Training loss: {running_loss/len(shadow_train_loader)}\")\n",
        "\n",
        "#save the model\n",
        "print(\"Our model: \\n\\n\", shadow_model, '\\n')\n",
        "torch.save(shadow_model.state_dict(), project_path+'/shadow_checkpoint.pth')\n",
        "print('Finished Training the Shadow model')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch : 1/20.. Training loss: 1.8326000490456895\n",
            "\n",
            "Epoch : 2/20.. Training loss: 1.4963748729442392\n",
            "\n",
            "Epoch : 3/20.. Training loss: 1.3100296827533362\n",
            "\n",
            "Epoch : 4/20.. Training loss: 1.1765838185387194\n",
            "\n",
            "Epoch : 5/20.. Training loss: 1.0515979274993053\n",
            "\n",
            "Epoch : 6/20.. Training loss: 0.9692009949242063\n",
            "\n",
            "Epoch : 7/20.. Training loss: 0.8906403121817142\n",
            "\n",
            "Epoch : 8/20.. Training loss: 0.8339197263883813\n",
            "\n",
            "Epoch : 9/20.. Training loss: 0.7720440609756943\n",
            "\n",
            "Epoch : 10/20.. Training loss: 0.736395839725614\n",
            "\n",
            "Epoch : 11/20.. Training loss: 0.699759199758015\n",
            "\n",
            "Epoch : 12/20.. Training loss: 0.6594476912103956\n",
            "\n",
            "Epoch : 13/20.. Training loss: 0.6243988204261531\n",
            "\n",
            "Epoch : 14/20.. Training loss: 0.591829966143955\n",
            "\n",
            "Epoch : 15/20.. Training loss: 0.5700706407675505\n",
            "\n",
            "Epoch : 16/20.. Training loss: 0.5380912215336967\n",
            "\n",
            "Epoch : 17/20.. Training loss: 0.51999789534513\n",
            "\n",
            "Epoch : 18/20.. Training loss: 0.4819958789078781\n",
            "\n",
            "Epoch : 19/20.. Training loss: 0.4617173884283094\n",
            "\n",
            "Epoch : 20/20.. Training loss: 0.4515774054238406\n",
            "Our model: \n",
            "\n",
            " CNN(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU(inplace)\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU(inplace)\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc_layer): Sequential(\n",
            "    (0): Dropout(p=0.1)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU(inplace)\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU(inplace)\n",
            "    (5): Dropout(p=0.1)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (7): LogSoftmax()\n",
            "  )\n",
            ") \n",
            "\n",
            "Finished Training the Shadow model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NSkq8iYxBqd",
        "colab_type": "code",
        "outputId": "47f496ea-730a-4cdf-dc5b-cfa23b700bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# calculate the accuracy of the Shadow Model\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        #print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 12500 test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 12500 test images: 76 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hljHs-PtxGUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = CNN()\n",
        "    model.load_state_dict(checkpoint)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTgQPb_qxJdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1# pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "shadow_train_sampler = SubsetRandomSampler(shadow_train_idx) # Pytorch function\n",
        "shadow_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_train_sampler)\n",
        "\n",
        "shadow_out_sampler = SubsetRandomSampler(shadow_out_idx) # Pytorch function\n",
        "shadow_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=shadow_out_sampler)\n",
        "\n",
        "# divide and load Target in and out\n",
        "target_train_sampler = SubsetRandomSampler(target_train_idx) # Pytorch function\n",
        "target_train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_train_sampler)\n",
        "\n",
        "target_out_sampler = SubsetRandomSampler(target_out_idx) # Pytorch function\n",
        "target_out_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=target_out_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0kP_-62ljFE",
        "colab_type": "code",
        "outputId": "25117734-5a67-4428-bbef-c57353518480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the model\n",
        "load_shadow_model = load_checkpoint(project_path+'/shadow_checkpoint.pth')\n",
        "load_shadow_model = load_shadow_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_shadow_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "\n",
        "labels_0 = 0#np.zeros(1)\n",
        "labels_1 = 1#np.ones(1)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in shadow_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_shadow_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "print(predictions[0])  \n",
        "print(predictions[13000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([3.6251895e-02, 3.8134298e-05, 8.2505488e-01, 3.7621457e-02,\n",
            "       1.7927686e-02, 5.9927203e-02, 1.9835418e-02, 3.2158606e-03,\n",
            "       8.5099542e-05, 4.2272895e-05], dtype=float32), 1]\n",
            "[array([0.04163226, 0.003633  , 0.03022603, 0.20623973, 0.5958088 ,\n",
            "       0.02458105, 0.01731993, 0.03958119, 0.01061957, 0.03035842],\n",
            "      dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvjb9z7pxltx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new dataset of the shape [predictions(shadow_in), 1], [predicitons(shadow_out), 0] and zip them together\n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/shadow.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2SczzYSxo31",
        "colab_type": "code",
        "outputId": "fb650a7c-0032-4218-cc52-f3aabe87c5ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/shadow.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    predictionsList = pickle.load(filehandle)\n",
        "    \n",
        "print(predictionsList[0])  \n",
        "print(predictionsList[13000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([3.6251895e-02, 3.8134298e-05, 8.2505488e-01, 3.7621457e-02,\n",
            "       1.7927686e-02, 5.9927203e-02, 1.9835418e-02, 3.2158606e-03,\n",
            "       8.5099542e-05, 4.2272895e-05], dtype=float32), 1]\n",
            "[array([0.04163226, 0.003633  , 0.03022603, 0.20623973, 0.5958088 ,\n",
            "       0.02458105, 0.01731993, 0.03958119, 0.01061957, 0.03035842],\n",
            "      dtype=float32), 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHCg4dLQNLXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate the recall and precision of your attack network using the Target_out and Target_in datasets\n",
        "# to do so, take a random numer of datapoints, run them throw the target model,\n",
        "#load the model\n",
        "load_target_model = load_checkpoint(project_path+'/target_checkpoint.pth')\n",
        "load_target_model = load_target_model.cuda()\n",
        "\n",
        "# freeze the Shadow model \n",
        "for param in load_target_model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "# make predictions on both datasets (shadow_in and shdow_out)\n",
        "predictions = []\n",
        "label_size = (1,1)\n",
        "\n",
        "labels_0 = 0\n",
        "labels_1 = 1\n",
        "with torch.no_grad():\n",
        "    for images, labels in target_train_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_1])   \n",
        "with torch.no_grad():\n",
        "    for images, labels in target_out_loader:\n",
        "        # sending tensors to GPU\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        logps = load_target_model(images)\n",
        "        ps = torch.exp(logps) \n",
        "        ps = ps.cpu()\n",
        "        pred = ps.data.numpy()\n",
        "        predictions.append([pred[0],labels_0]) \n",
        "        \n",
        "#save the dataset\n",
        "import pickle\n",
        "\n",
        "with open(project_path+'/data/target.data', 'wb') as filehandle:\n",
        "    pickle.dump(predictions, filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGKtP1y5NdAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    testloader = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q7skm_XNv1n",
        "colab_type": "code",
        "outputId": "0e9e850c-a5b6-42d3-a3fa-fdb26d7ba004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "total_size = len(predictionsList)\n",
        "split1 = total_size // 4\n",
        "split1 = total_size - split1 \n",
        "split2 = split1*2\n",
        "indices = list(range(total_size))\n",
        "\n",
        "# two groups to train the shadow (in and out)\n",
        "train_idx = indices[:] \n",
        "test_idx = indices[split1:] \n",
        "print(f'No.of train date {len(train_idx)} and No.of test data {len(test_idx)}')\n",
        "batch_size = 10 # pick your own\n",
        "\n",
        "# divide and load shadow train in and out\n",
        "train_sampler = SubsetRandomSampler(train_idx) # Pytorch function\n",
        "train_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "test_sampler = SubsetRandomSampler(test_idx) # Pytorch function\n",
        "test_loader = torch.utils.data.DataLoader(predictionsList, batch_size=batch_size, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of train date 25000 and No.of test data 6250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ymKnj7QpdDG",
        "colab_type": "code",
        "outputId": "9f265f33-10d2-47a5-9e19-d50fb1d51a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# create the Attack Model: A NN binary classifier {0, 1}\n",
        "# the input to this model is the propability distribution vector of size 10\n",
        "# and the output is either 0 (input was not included in training) or 1\n",
        "from torch.autograd import Variable\n",
        "attack_model = nn.Sequential(nn.Linear(10, 20),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(20, 26),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(26, 16),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(16, 8),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(8, 2),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "attack_model = attack_model.cuda()\n",
        "attack_criterion = nn.CrossEntropyLoss()\n",
        "attack_optimizer = optim.Adam(attack_model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for outputs, labels in train_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        attack_optimizer.zero_grad()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        #print(pred.data, labels)\n",
        "        loss = attack_criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        attack_optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(predictionsList)}\")\n",
        "        \n",
        "torch.save(attack_model.state_dict(), project_path+'/attack_checkpoint.pth')\n",
        "print('Finished Training the Attack model')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.06933208810091018\n",
            "Training loss: 0.0693327307343483\n",
            "Training loss: 0.06933217011451721\n",
            "Training loss: 0.0693206783413887\n",
            "Training loss: 0.06933407670974731\n",
            "Finished Training the Attack model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-3qQKi2QoV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the dataset\n",
        "with open(project_path+'/data/target.data', 'rb') as filehandle:\n",
        "    # read the data as binary data stream\n",
        "    validation = pickle.load(filehandle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zv7p1ffQqgk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1 # pick your own\n",
        "\n",
        "validation_sampler = SubsetRandomSampler(indices[6250:18250]) # randomly picking 5000 data items\n",
        "validation_loader = torch.utils.data.DataLoader(validation, batch_size=batch_size, sampler=validation_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szCihJAsQt1K",
        "colab_type": "code",
        "outputId": "29cfdb6b-9482-458a-b4fc-6d9fc644d954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#input the output of the target model to your attack network \n",
        "# you already know the target_in and target_out samples, so use that info to evaluate the attack model\n",
        "correct = 0\n",
        "incorrect = 0\n",
        "total = 0\n",
        "tp = 0\n",
        "tn = 0\n",
        "fp = 0\n",
        "fn = 0\n",
        "with torch.no_grad():\n",
        "    for outputs, labels in validation_loader:\n",
        "        # sending tensors to GPU\n",
        "        outputs = outputs.cuda().float()\n",
        "        labels = labels.cuda().long()\n",
        "        pred = torch.exp(attack_model(outputs))\n",
        "        predicted = torch.argmax(pred.data)\n",
        "        #print('\\n',pred.data, predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.item() == labels.item())\n",
        "        tp += ((predicted.item() == labels.item()) and (predicted.item() == 1))\n",
        "        tn += ((predicted.item() == labels.item()) and (predicted.item() == 0))\n",
        "        fp += ((predicted.item() != labels.item()) and (predicted.item() == 1))\n",
        "        fn += ((predicted.item() != labels.item()) and (predicted.item() == 0))\n",
        "        #print(predicted.item(),labels.item(),correct)\n",
        "incorrect = total- correct\n",
        "print(f'TP : {tp}, TN : {tn}, FP : {fp}, FN : {fn}')\n",
        "pre = tp/(tp+fp)\n",
        "rec = tp/(tp+fn)\n",
        "print(f'Precision {pre*100}')\n",
        "print(f'Recall {rec*100}')\n",
        "print(f'F1 Score {2*((pre*rec)/(pre+rec))*100}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP : 6250, TN : 0, FP : 5750, FN : 0\n",
            "Precision 52.083333333333336\n",
            "Recall 100.0\n",
            "F1 Score 68.4931506849315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMsyCgziqeaa",
        "colab_type": "text"
      },
      "source": [
        "Great! At this point, you must have created a succesfful attack model that can detect whether a datapoint was used in training a target mode or not. \n",
        "* A successful attack model is one with a precision/recall higher than 85% -- you are using same architecture and are aware of the data classes\n",
        "\n",
        " \n",
        " Can you suggest any defense mechanism? If yes, Apply them to your solution and re-evaluate your attack model. How did your defense mecanism affect the accuracy of the target model? How did it affect the recall and precision of the Attack model?"
      ]
    }
  ]
}